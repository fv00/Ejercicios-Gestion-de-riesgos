---
title: "Ejercicios basicos de modelamiento"
author: "Santiago Franco"
date: "12/5/2022"
output:
  pdf_document: default
  html_document: default
---


```{r}
library(ggplot2)
library(grid)
library(gridExtra)
library(dplyr)
library(magrittr)
library(ROCit)
library(randomForest)
library(stringr)
library(stats)
library(glmtoolbox)
library(PDQutils)
require(GoFKernel)
```

```{r}
mapa_de_calor <- function(categoria1, categoria2, relleno){
  p <- ggplot(aes(x=categoria1, y=categoria2, fill= relleno)) + geom_tile()
  return(p)
}
```



```{r}
datos <- read.table("base6.dat", header = TRUE)
tabla_mostrar <- head(datos) %>%
  mutate_if(is.numeric, round, digits=2)
names(tabla_mostrar) <- str_replace_all(names(tabla_mostrar), "\\.", ' ')
(names(tabla_mostrar))
grid.table(tabla_mostrar, theme=ttheme_default(base_size = 4))
```

## Preparación datos para el modelo:

```{r}
## Variables categóricas:
datos$tamaño <- as.factor(datos$tamaño)
datos$sector <- as.factor(datos$sector)
datos$Default <- as.factor(datos$Default)


## Datos para el modelo
datos_modelo <- datos[-c(3)]
```

## Análisis descriptivo de los datos

### Variable respuesta

```{r}
ggplot(data=datos, aes(x=Default)) + 
  geom_bar() + 
  geom_text(stat='count', aes(label=round(..count../sum(..count..),2)), vjust=-1) + 
  ylim(0,770) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank()) + ggtitle('Cantidad de carteras en default')
```
A simple vista se observa que se tienen dos categorías desbalanceadas en la base de datos para establecer el modelo.


### Tamaño de la empresa
```{r}
### Heatmap
p <- ggplot(data=datos, aes(x=tamaño, fill=Default)) +
  geom_bar(position = 'dodge') +
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank()) 
p
```

### Sector

```{r}
### Heatmap
p <- ggplot(data=datos, aes(x=sector, fill=Default)) +
  geom_bar(position = 'dodge') +
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank()) 
p
```


### Margen Operativo
```{r}
### Grafica violín
ggplot(data=datos, aes(y=Default,
                       x=UtilNeta.Patrimonio,
                       fill=Default)) +
  geom_boxplot(trim = F)
```


### Margen Ebitda
```{r}
### Grafica violín
ggplot(data=datos, aes(y=Default,
                       x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot()
```


### Ebitda/ Gasto Financiero

```{r}
### Grafica violín
ggplot(data=datos, aes(x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot(position = 'dodge')
```


### Pasivo Fcro. Total / (Ebitda - Gasto Fcro)

```{r}
### Grafica violín
ggplot(data=datos, aes(x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot(position = 'dodge')
```


### Margen Neto

```{r}
### Grafica violín
ggplot(data=datos, aes(x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot(position = 'dodge')
```

### Ebitda / Activo Total
```{r}
### Grafica violín
ggplot(data=datos, aes(x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot(position = 'dodge')
```

### SALDO DEUDA
```{r}
### Grafica violín
ggplot(data=datos, aes(x=Ebitda.ActivoTotal,
                       fill=Default)) +
  geom_boxplot(position = 'dodge')
```


##Implementacion modelo logit

```{r}
datos_modelo <- datos[4:11]
modelo_logit <- glm(Default ~ ., family = binomial, data=datos_modelo)
summary(modelo_logit)
```
### Depuración del modelo:

A simple vista se observa que las variables categóricas pertenecientes a la base de datos no tienen aparentemente diferencias signficativas respecto a la cantidad de default que hay asociado a una categoría, es decir, aparentemente la probabilidad de default es homogenea entre carteras. Por lo que se realiza un modelo sin incluir las variables categóricas:

```{r}
datos_modelo_1 <- datos[5:11]
modelo_depuracion1 <-  glm(Default ~ ., family = binomial, data=datos_modelo_1)
summary(modelo_depuracion1)
```
```{r}
data.frame(cor(datos_modelo_1[1:6]))
```
```{r}
datos_modelo_final <- datos[c('UtilNeta.Patrimonio', 'Ciclo.Efectivo', 'Pasivo.Activos', 'Default')]
modelo_final <- glm(Default ~ ., family = binomial, data=datos_modelo_final)
summary(modelo_final)
```

###Tabla de coeficientes

```{r}
summary(modelo_final)
```
###Valores P

###Pruebas de ajuste

```{r}
hltest(modelo_final)
```

### Matriz de confusión

```{r}
predicciones_originales <- predict(modelo_final, type = 'response')
predicciones <- ifelse(predicciones_originales >0.2, 1, 0)
table(predicciones, datos$Default)
```
###Curva ROC

```{r}
roc <- rocit(score = predicciones_originales, class=datos$Default)
plot(roc)
```

## Gráfica de las densidades de las probabilidades de default estimadas por modelo logit
```{r}
d.hat = modelo_final$fitted.values
plot(density(d.hat))
```
* escribir al final las 4 gráficas con un marplot

##Implementacion de random forest

```{r}
rf <- randomForest(Default ~ ., data = datos_modelo_final)
```

```{r}
library(rpart)
library(party)
```

```{r}
x <- ctree(Default ~ ., data = datos_modelo_final)
plot(x, type='simple')
```

## Gráfica de las densidades de las probabilidades de default estimadas por bosques aleatorios

```{r}
pesos_rf <- rf$votes[,2]
plot(density(pesos_rf))
```


###Curva ROC arboles aleatorios
```{r}
roc_rf <- rocit(pesos_rf, class = datos$Default)
plot(roc_rf)
```


##Implementacion de Knn

```{r}
library(kernlab)
library(caret)
library(randomForest)
```

```{r}
modelos_knn <- list()
for (i in 1:10) {
  modelo_knn <- knn3(Default ~ ., data=datos_modelo_final, k=i)
  modelos_knn[[i]] <- sum(predict(modelo_knn, newdata=datos_modelo_final)[,2] == datos$Default)/length(datos$Default)
}
#K=2
modelo_knn <- knn3(Default ~ ., data=datos_modelo_final, k=2)
pesos <- predict(modelo_knn, newdata=datos_modelo_final, type ="prob")[,2]
```

```{r}
codos <- unlist(modelos_knn)
plot(codos, type="l")
```


###Curva ROC

```{r}
roc_knn <- rocit(score=pesos, class=datos$Default)
plot(roc_knn)
##Depurar !!
```

## Gráfica de las densidades de las probabilidades de default estimadas por knn

```{r}
plot(density(pesos))
```

##Implementacion de SVM

```{r}
library(forecast)
library(ISLR)
library(e1071)
```


```{r}
##Tune
set.seed(123)

modelos <- list()
ajustados <- list()
for (i in 1:200) {
  modelo <- svm(Default~., data=datos_modelo_final,kernel= "radial", cost=i)
  modelos[[i]] <- modelo
  ajustados[[i]] <- sum(modelo$fitted==1)
}
```

```{r}
modelo_svm_final <- svm(Default~., data=datos_modelo_final,kernel= "radial", cost=200, probability = TRUE)
```

```{r}
predicciones_modelo_svm_final <- predict(modelo_svm_final, datos_modelo_final,  probability= TRUE)
probabilidades_default_svm <- attr(predicciones_modelo_svm_final, 'probabilities')[,2]
plot(density(probabilidades_default_svm))
```
### Curva ROC
```{r}
roc_svm <- rocit(score=probabilidades_default_svm, class=datos_modelo_final$Default)
plot(roc_svm)
```

###Curva ROC

### GRÁFICOS DE DENSIDAD PARA TODOS LOS MODELOS
```{r}
par(mfrow = c(2,2))
plot(density(d.hat), main = "Densidad Modelo Logit")
plot(density(pesos_rf), main = "Densidad Bosques Aleatorios")
plot(density(probabilidades_default_svm), main="Densidad SVM")
plot(density(pesos), main="Densidad Knn")
```


## Curva ROC para todos los modelos

```{r}
par(mfrow = c(2,2))
plot(roc)
plot(roc_rf)
plot(roc_knn)
plot(roc_svm)
```

## AUC de todos los modelos

```{r}
titulos <- c('Knn', 'SVM', 'logit', 'RF')
AUCs <- c(roc_knn$AUC[1], roc_svm$AUC[1], roc$AUC[1], roc_rf$AUC)

tabla <- rbind(AUCs)
colnames(tabla) <- titulos
tabla
```

Se decide utilizar el modelo knn

## Simulación:


### Mejor modelo según AUC
Se particionan los datos según su probabilidad de impago:

```{r}
datos_mejor_modelo <- cbind(datos[,c('Default', 'Saldos')], Impago=predicciones_originales)
```

Se particionan los datos según su probabilidad estimada de impago:
```{r}
mejor_modelo_pago <- datos_mejor_modelo[datos_mejor_modelo['Impago'] < 0.1,]
mejor_modelo_impago <- datos_mejor_modelo[datos_mejor_modelo['Impago'] > 0.1,]
```

```{r}
lj = mejor_modelo_pago[['Saldos']]
pj = mejor_modelo_pago[['Impago']]
qj = 1 - pj
```

Se calculan cumulantes para ambos subconjuntos (En este caso se asume que $w_i=0$:
```{r}
#Cumulantes para L1
kappa_mejor_l1 = double(4)
kappa_mejor_l1[1] = sum(lj*pj)
kappa_mejor_l1[2] = sum(pj*qj*lj^2 )
kappa_mejor_l1[3] = sum(lj^3*pj*qj*(qj - pj))
kappa_mejor_l1[4] = sum(lj^4*pj*qj*(pj - 4*pj*qj  + qj^2))
```

```{r}
lj = mejor_modelo_impago[['Saldos']]
pj = mejor_modelo_impago[['Impago']]
qj = 1 - pj

#Cumulantes para L2
kappa_mejor_l2 = double(4)
kappa_mejor_l2[1] = sum(lj*pj)
kappa_mejor_l2[2] = sum(pj*qj*lj^2 )
kappa_mejor_l2[3] = sum(lj^3*pj*qj*(qj - pj))
kappa_mejor_l2[4] = sum(lj^4*pj*qj*(pj - 4*pj*qj  + qj^2))
```

```{r}
set.seed(1)
Laj = cumulant2moment(kappa_mejor_l1) 

mx = kappa_mejor_l1[1]+4*sqrt(kappa_mejor_l1[2])
mx0 = kappa_mejor_l1[1]-2*sqrt(kappa_mejor_l1[2])


xe = seq(0,mx, by=10000000)


# estimación de la densidad de L 
fx.gch = dapx_gca(xe, raw.moments=Laj, 
                  support=c(0,mx), 
                  basis='gamma')

# acumulada
FL1_mejor_modelo = function(t){
  papx_gca(t, raw.moments=Laj, 
           support=c(0,mx), 
           basis='gamma')}

plot(xe,FL1_mejor_modelo(xe))
plot(xe, fx.gch)

inversa_L1_mejor_modelo <- inverse(FL1_mejor_modelo,lower=0,upper=mx)

muestra <- runif(1000)
resultado1 <- sapply(muestra, inversa_L1_mejor_modelo)
hist(resultado1)
```

```{r}
set.seed(1)
Laj2 = cumulant2moment(kappa_mejor_l2) 

mx = kappa_mejor_l2[1]+4*sqrt(kappa_mejor_l2[2])
mx0 = kappa_mejor_l2[1]-2*sqrt(kappa_mejor_l2[2])


xe = seq(0,mx, by=10000000)


# estimación de la densidad de L 
fx2.gch = dapx_gca(xe, raw.moments=Laj2, 
                  support=c(0,mx), 
                  basis='gamma')

# acumulada
FL2_mejor_modelo = function(t){
  papx_gca(t, raw.moments=Laj2, 
           support=c(0,mx), 
           basis='gamma')}

plot(xe,FL2_mejor_modelo(xe))
plot(xe, fx2.gch)

inversa_L2_mejor_modelo <- inverse(FL2_mejor_modelo,lower=0,upper=mx)

muestra <- runif(1000)
resultado2 <- sapply(muestra, inversa_L2_mejor_modelo)
hist(resultado2)
```

```{r}
resultados_mejor = resultado1 + resultado2
hist(resultados_mejor)
```
Tvar resultados simulados
```{r}
t_var_mejor_modelo <- quantile(resultado, probs=0.95)
t_var_mejor_modelo
```

### Peor modelo según AUC
```{r}
datos_peor_modelo <- cbind(datos[,c('Default', 'Saldos')], Impago = pesos_rf)
peor_modelo_pago <- datos_peor_modelo[datos_peor_modelo['Impago'] < 0.1,]
peor_modelo_impago <- datos_peor_modelo[datos_peor_modelo['Impago'] > 0.1,]
```

Se calculan cumulantes para ambos subconjuntos (En este caso se asume que $w_i=0$:
```{r}
lj = peor_modelo_pago[['Saldos']]
pj = peor_modelo_pago[['Impago']]
qj = 1 - pj

#Cumulantes para L1
kappa_peor_l1 = double(4)
kappa_peor_l1[1] = sum(lj*pj)
kappa_peor_l1[2] = sum(pj*qj*lj^2 )
kappa_peor_l1[3] = sum(lj^3*pj*qj*(qj - pj))
kappa_peor_l1[4] = sum(lj^4*pj*qj*(pj - 4*pj*qj  + qj^2))
```

```{r}
lj = peor_modelo_impago[['Saldos']]
pj = peor_modelo_impago[['Impago']]
qj = 1 - pj

#Cumulantes para L2
kappa_peor_l2 = double(4)
kappa_peor_l2[1] = sum(lj*pj)
kappa_peor_l2[2] = sum(pj*qj*lj^2 )
kappa_peor_l2[3] = sum(lj^3*pj*qj*(qj - pj))
kappa_peor_l2[4] = sum(lj^4*pj*qj*(pj - 4*pj*qj  + qj^2))
```

```{r}
set.seed(1)
Laj = cumulant2moment(kappa_peor_l1) 

mx = kappa_peor_l1[1]+4*sqrt(kappa_peor_l1[2])
mx0 = kappa_peor_l1[1]-2*sqrt(kappa_peor_l1[2])


xe = seq(0,mx, by=10000000)


# estimación de la densidad de L 
fx.gch = dapx_gca(xe, raw.moments=Laj, 
                  support=c(0,mx), 
                  basis='gamma')

# acumulada
FL1_peor_modelo = function(t){
  papx_gca(t, raw.moments=Laj, 
           support=c(0,mx), 
           basis='gamma')}

plot(xe,FL1_peor_modelo(xe))
plot(xe, fx.gch)

inversa_L1_peor_modelo <- inverse(FL1_peor_modelo,lower=0,upper=mx)

muestra <- runif(1000)
resultado_peor1 <- sapply(muestra, inversa_L1_peor_modelo)
hist(resultado_peor1)
```

```{r}
set.seed(1)
Laj2 = cumulant2moment(kappa_peor_l2) 

mx = kappa_peor_l2[1]+4*sqrt(kappa_peor_l2[2])
mx0 = kappa_peor_l2[1]-2*sqrt(kappa_peor_l2[2])


xe = seq(0,mx, by=10000000)


# estimación de la densidad de L 
fx2.gch = dapx_gca(xe, raw.moments=Laj2, 
                  support=c(0,mx), 
                  basis='gamma')

# acumulada
FL2_peor_modelo = function(t){
  papx_gca(t, raw.moments=Laj2, 
           support=c(0,mx), 
           basis='gamma')}

plot(xe,FL2_peor_modelo(xe))
plot(xe, fx2.gch)

inversa_L2_peor_modelo <- inverse(FL2_peor_modelo,lower=0,upper=mx)

muestra <- runif(1000)
resultado_peor2 <- sapply(muestra, inversa_L2_peor_modelo)
hist(resultado_peor2)
```

```{r}
resultados_peor <- resultado_peor1 + resultado_peor2
hist(resultados_peor)
```
```{r}
t_var_peor_modelo <- quantile(resultados_peor, probs=0.95)
t_var_peor_modelo
```

## TVaR marginal:

### Peor modelo:
```{r}
t.var_l1_peor <- mean(resultados_peor*ifelse(resultados_peor>t_var_peor_modelo, 1,0))/0.95
t.var_l1_peor
```

### Mejor modelo:
```{r}
t.var_l1_mejor <- mean(resultados_mejor*ifelse(resultados_mejor>t_var_mejor_modelo, 1,0))/0.95
t.var_l1_mejor
```
